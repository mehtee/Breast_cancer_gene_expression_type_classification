{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T23:49:41.400435Z","iopub.execute_input":"2023-09-10T23:49:41.400831Z","iopub.status.idle":"2023-09-10T23:49:41.416651Z","shell.execute_reply.started":"2023-09-10T23:49:41.400800Z","shell.execute_reply":"2023-09-10T23:49:41.415497Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"/kaggle/input/breast-cancer-gene-expression-cumida/Breast_GSE45827.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/breast-cancer-gene-expression-cumida/Breast_GSE45827.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:26.804653Z","iopub.execute_input":"2023-09-11T00:30:26.805068Z","iopub.status.idle":"2023-09-11T00:30:43.828773Z","shell.execute_reply.started":"2023-09-11T00:30:26.805037Z","shell.execute_reply":"2023-09-11T00:30:43.827153Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"df.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:43.831273Z","iopub.execute_input":"2023-09-11T00:30:43.831626Z","iopub.status.idle":"2023-09-11T00:30:43.848785Z","shell.execute_reply.started":"2023-09-11T00:30:43.831596Z","shell.execute_reply":"2023-09-11T00:30:43.847502Z"},"trusted":true},"execution_count":235,"outputs":[{"execution_count":235,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:43.850579Z","iopub.execute_input":"2023-09-11T00:30:43.851288Z","iopub.status.idle":"2023-09-11T00:30:43.893253Z","shell.execute_reply.started":"2023-09-11T00:30:43.851248Z","shell.execute_reply":"2023-09-11T00:30:43.892242Z"},"trusted":true},"execution_count":236,"outputs":[{"execution_count":236,"output_type":"execute_result","data":{"text/plain":"   samples   type  1007_s_at   1053_at    117_at    121_at  1255_g_at  \\\n0       84  basal   9.850040  8.097927  6.424728  7.353027   3.029122   \n1       85  basal   9.861357  8.212222  7.062593  7.685578   3.149468   \n2       87  basal  10.103478  8.936137  5.735970  7.687822   3.125931   \n3       90  basal   9.756875  7.357148  6.479183  6.986624   3.181638   \n4       91  basal   9.408330  7.746404  6.693980  7.333426   3.169923   \n\n    1294_at   1316_at   1320_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n0  6.880079  4.963740  4.408328  ...             12.229711   \n1  7.542283  5.129607  4.584418  ...             12.178531   \n2  6.562369  4.813449  4.425195  ...             12.125108   \n3  7.802344  5.490982  4.567956  ...             12.111235   \n4  7.610457  5.372469  4.424426  ...             12.173642   \n\n   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n0             11.852955            13.658701            13.477698   \n1             11.809408            13.750086            13.470146   \n2             11.725766            13.621732            13.295080   \n3             11.719215            13.743108            13.508861   \n4             11.861296            13.797774            13.542206   \n\n   AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n0        6.265781        5.016196        4.901594         2.966657   \n1        6.771853        5.291005        5.405839         2.934763   \n2        6.346952        5.171403        5.184286         2.847684   \n3        6.610284        5.193356        5.086569         3.031602   \n4        6.414354        5.040202        5.235318         2.956232   \n\n   AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n0         3.508495         3.301999  \n1         3.687666         3.064299  \n2         3.550597         3.158535  \n3         3.524981         3.272665  \n4         3.445501         3.193947  \n\n[5 rows x 54677 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>samples</th>\n      <th>type</th>\n      <th>1007_s_at</th>\n      <th>1053_at</th>\n      <th>117_at</th>\n      <th>121_at</th>\n      <th>1255_g_at</th>\n      <th>1294_at</th>\n      <th>1316_at</th>\n      <th>1320_at</th>\n      <th>...</th>\n      <th>AFFX-r2-Ec-bioD-3_at</th>\n      <th>AFFX-r2-Ec-bioD-5_at</th>\n      <th>AFFX-r2-P1-cre-3_at</th>\n      <th>AFFX-r2-P1-cre-5_at</th>\n      <th>AFFX-ThrX-3_at</th>\n      <th>AFFX-ThrX-5_at</th>\n      <th>AFFX-ThrX-M_at</th>\n      <th>AFFX-TrpnX-3_at</th>\n      <th>AFFX-TrpnX-5_at</th>\n      <th>AFFX-TrpnX-M_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84</td>\n      <td>basal</td>\n      <td>9.850040</td>\n      <td>8.097927</td>\n      <td>6.424728</td>\n      <td>7.353027</td>\n      <td>3.029122</td>\n      <td>6.880079</td>\n      <td>4.963740</td>\n      <td>4.408328</td>\n      <td>...</td>\n      <td>12.229711</td>\n      <td>11.852955</td>\n      <td>13.658701</td>\n      <td>13.477698</td>\n      <td>6.265781</td>\n      <td>5.016196</td>\n      <td>4.901594</td>\n      <td>2.966657</td>\n      <td>3.508495</td>\n      <td>3.301999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85</td>\n      <td>basal</td>\n      <td>9.861357</td>\n      <td>8.212222</td>\n      <td>7.062593</td>\n      <td>7.685578</td>\n      <td>3.149468</td>\n      <td>7.542283</td>\n      <td>5.129607</td>\n      <td>4.584418</td>\n      <td>...</td>\n      <td>12.178531</td>\n      <td>11.809408</td>\n      <td>13.750086</td>\n      <td>13.470146</td>\n      <td>6.771853</td>\n      <td>5.291005</td>\n      <td>5.405839</td>\n      <td>2.934763</td>\n      <td>3.687666</td>\n      <td>3.064299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87</td>\n      <td>basal</td>\n      <td>10.103478</td>\n      <td>8.936137</td>\n      <td>5.735970</td>\n      <td>7.687822</td>\n      <td>3.125931</td>\n      <td>6.562369</td>\n      <td>4.813449</td>\n      <td>4.425195</td>\n      <td>...</td>\n      <td>12.125108</td>\n      <td>11.725766</td>\n      <td>13.621732</td>\n      <td>13.295080</td>\n      <td>6.346952</td>\n      <td>5.171403</td>\n      <td>5.184286</td>\n      <td>2.847684</td>\n      <td>3.550597</td>\n      <td>3.158535</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90</td>\n      <td>basal</td>\n      <td>9.756875</td>\n      <td>7.357148</td>\n      <td>6.479183</td>\n      <td>6.986624</td>\n      <td>3.181638</td>\n      <td>7.802344</td>\n      <td>5.490982</td>\n      <td>4.567956</td>\n      <td>...</td>\n      <td>12.111235</td>\n      <td>11.719215</td>\n      <td>13.743108</td>\n      <td>13.508861</td>\n      <td>6.610284</td>\n      <td>5.193356</td>\n      <td>5.086569</td>\n      <td>3.031602</td>\n      <td>3.524981</td>\n      <td>3.272665</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>91</td>\n      <td>basal</td>\n      <td>9.408330</td>\n      <td>7.746404</td>\n      <td>6.693980</td>\n      <td>7.333426</td>\n      <td>3.169923</td>\n      <td>7.610457</td>\n      <td>5.372469</td>\n      <td>4.424426</td>\n      <td>...</td>\n      <td>12.173642</td>\n      <td>11.861296</td>\n      <td>13.797774</td>\n      <td>13.542206</td>\n      <td>6.414354</td>\n      <td>5.040202</td>\n      <td>5.235318</td>\n      <td>2.956232</td>\n      <td>3.445501</td>\n      <td>3.193947</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 54677 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['type'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:43.895514Z","iopub.execute_input":"2023-09-11T00:30:43.895877Z","iopub.status.idle":"2023-09-11T00:30:43.905892Z","shell.execute_reply.started":"2023-09-11T00:30:43.895847Z","shell.execute_reply":"2023-09-11T00:30:43.904982Z"},"trusted":true},"execution_count":237,"outputs":[{"execution_count":237,"output_type":"execute_result","data":{"text/plain":"array(['basal', 'HER', 'cell_line', 'normal', 'luminal_A', 'luminal_B'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"numerical_columns = df.columns\nnumerical_columns = numerical_columns[2:]\nmeans = pd.DataFrame(data = df.groupby('type')[numerical_columns].mean())","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:43.907516Z","iopub.execute_input":"2023-09-11T00:30:43.907928Z","iopub.status.idle":"2023-09-11T00:30:44.081944Z","shell.execute_reply.started":"2023-09-11T00:30:43.907897Z","shell.execute_reply":"2023-09-11T00:30:44.080946Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"means","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:44.083189Z","iopub.execute_input":"2023-09-11T00:30:44.084293Z","iopub.status.idle":"2023-09-11T00:30:44.125088Z","shell.execute_reply.started":"2023-09-11T00:30:44.084258Z","shell.execute_reply":"2023-09-11T00:30:44.123956Z"},"trusted":true},"execution_count":239,"outputs":[{"execution_count":239,"output_type":"execute_result","data":{"text/plain":"           1007_s_at   1053_at    117_at    121_at  1255_g_at   1294_at  \\\ntype                                                                      \nHER        10.390339  7.665946  6.209118  7.282768   3.220987  7.093613   \nbasal      10.030862  8.016134  6.517833  7.277322   3.195922  7.178895   \ncell_line   9.904857  8.808437  5.286330  7.584341   3.239354  6.533271   \nluminal_A  10.517195  6.955149  6.175663  7.324082   3.112149  7.635086   \nluminal_B  10.766478  7.458639  6.488550  7.322810   3.148384  7.562368   \nnormal     10.219646  6.428852  5.527662  7.587111   3.322261  8.135556   \n\n            1316_at   1320_at  1405_i_at   1431_at  ...  AFFX-r2-Ec-bioD-3_at  \\\ntype                                                ...                         \nHER        5.376958  4.695372   7.865080  3.695983  ...             12.227238   \nbasal      5.188827  4.724066   8.450465  3.646654  ...             12.241321   \ncell_line  5.176932  5.055129   6.057817  3.847932  ...             11.966830   \nluminal_A  5.297036  4.745397   7.534794  4.221277  ...             12.509749   \nluminal_B  5.446472  4.561497   7.896553  4.204526  ...             12.486872   \nnormal     5.758591  4.578178   7.615436  3.770717  ...             13.237785   \n\n           AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\ntype                                                                        \nHER                   11.706451            13.797838            13.513688   \nbasal                 11.700176            13.804383            13.532135   \ncell_line             11.342226            13.974987            13.708715   \nluminal_A             11.981518            14.236411            14.013724   \nluminal_B             11.949901            14.228569            14.026176   \nnormal                12.811179            14.495650            14.342022   \n\n           AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\ntype                                                                         \nHER              6.881973        5.229737        5.474393         2.892191   \nbasal            6.896607        5.203655        5.455047         2.889398   \ncell_line        8.038253        6.453257        6.883349         3.049190   \nluminal_A        8.243544        6.343402        6.975552         2.903851   \nluminal_B        8.157391        5.956942        6.701986         2.944812   \nnormal           9.338737        5.328691        6.631454         2.894163   \n\n           AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \ntype                                         \nHER               3.600173         3.167852  \nbasal             3.604728         3.135976  \ncell_line         3.843252         3.265455  \nluminal_A         3.576179         3.182598  \nluminal_B         3.641793         3.176325  \nnormal            3.522526         3.191712  \n\n[6 rows x 54675 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1007_s_at</th>\n      <th>1053_at</th>\n      <th>117_at</th>\n      <th>121_at</th>\n      <th>1255_g_at</th>\n      <th>1294_at</th>\n      <th>1316_at</th>\n      <th>1320_at</th>\n      <th>1405_i_at</th>\n      <th>1431_at</th>\n      <th>...</th>\n      <th>AFFX-r2-Ec-bioD-3_at</th>\n      <th>AFFX-r2-Ec-bioD-5_at</th>\n      <th>AFFX-r2-P1-cre-3_at</th>\n      <th>AFFX-r2-P1-cre-5_at</th>\n      <th>AFFX-ThrX-3_at</th>\n      <th>AFFX-ThrX-5_at</th>\n      <th>AFFX-ThrX-M_at</th>\n      <th>AFFX-TrpnX-3_at</th>\n      <th>AFFX-TrpnX-5_at</th>\n      <th>AFFX-TrpnX-M_at</th>\n    </tr>\n    <tr>\n      <th>type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>HER</th>\n      <td>10.390339</td>\n      <td>7.665946</td>\n      <td>6.209118</td>\n      <td>7.282768</td>\n      <td>3.220987</td>\n      <td>7.093613</td>\n      <td>5.376958</td>\n      <td>4.695372</td>\n      <td>7.865080</td>\n      <td>3.695983</td>\n      <td>...</td>\n      <td>12.227238</td>\n      <td>11.706451</td>\n      <td>13.797838</td>\n      <td>13.513688</td>\n      <td>6.881973</td>\n      <td>5.229737</td>\n      <td>5.474393</td>\n      <td>2.892191</td>\n      <td>3.600173</td>\n      <td>3.167852</td>\n    </tr>\n    <tr>\n      <th>basal</th>\n      <td>10.030862</td>\n      <td>8.016134</td>\n      <td>6.517833</td>\n      <td>7.277322</td>\n      <td>3.195922</td>\n      <td>7.178895</td>\n      <td>5.188827</td>\n      <td>4.724066</td>\n      <td>8.450465</td>\n      <td>3.646654</td>\n      <td>...</td>\n      <td>12.241321</td>\n      <td>11.700176</td>\n      <td>13.804383</td>\n      <td>13.532135</td>\n      <td>6.896607</td>\n      <td>5.203655</td>\n      <td>5.455047</td>\n      <td>2.889398</td>\n      <td>3.604728</td>\n      <td>3.135976</td>\n    </tr>\n    <tr>\n      <th>cell_line</th>\n      <td>9.904857</td>\n      <td>8.808437</td>\n      <td>5.286330</td>\n      <td>7.584341</td>\n      <td>3.239354</td>\n      <td>6.533271</td>\n      <td>5.176932</td>\n      <td>5.055129</td>\n      <td>6.057817</td>\n      <td>3.847932</td>\n      <td>...</td>\n      <td>11.966830</td>\n      <td>11.342226</td>\n      <td>13.974987</td>\n      <td>13.708715</td>\n      <td>8.038253</td>\n      <td>6.453257</td>\n      <td>6.883349</td>\n      <td>3.049190</td>\n      <td>3.843252</td>\n      <td>3.265455</td>\n    </tr>\n    <tr>\n      <th>luminal_A</th>\n      <td>10.517195</td>\n      <td>6.955149</td>\n      <td>6.175663</td>\n      <td>7.324082</td>\n      <td>3.112149</td>\n      <td>7.635086</td>\n      <td>5.297036</td>\n      <td>4.745397</td>\n      <td>7.534794</td>\n      <td>4.221277</td>\n      <td>...</td>\n      <td>12.509749</td>\n      <td>11.981518</td>\n      <td>14.236411</td>\n      <td>14.013724</td>\n      <td>8.243544</td>\n      <td>6.343402</td>\n      <td>6.975552</td>\n      <td>2.903851</td>\n      <td>3.576179</td>\n      <td>3.182598</td>\n    </tr>\n    <tr>\n      <th>luminal_B</th>\n      <td>10.766478</td>\n      <td>7.458639</td>\n      <td>6.488550</td>\n      <td>7.322810</td>\n      <td>3.148384</td>\n      <td>7.562368</td>\n      <td>5.446472</td>\n      <td>4.561497</td>\n      <td>7.896553</td>\n      <td>4.204526</td>\n      <td>...</td>\n      <td>12.486872</td>\n      <td>11.949901</td>\n      <td>14.228569</td>\n      <td>14.026176</td>\n      <td>8.157391</td>\n      <td>5.956942</td>\n      <td>6.701986</td>\n      <td>2.944812</td>\n      <td>3.641793</td>\n      <td>3.176325</td>\n    </tr>\n    <tr>\n      <th>normal</th>\n      <td>10.219646</td>\n      <td>6.428852</td>\n      <td>5.527662</td>\n      <td>7.587111</td>\n      <td>3.322261</td>\n      <td>8.135556</td>\n      <td>5.758591</td>\n      <td>4.578178</td>\n      <td>7.615436</td>\n      <td>3.770717</td>\n      <td>...</td>\n      <td>13.237785</td>\n      <td>12.811179</td>\n      <td>14.495650</td>\n      <td>14.342022</td>\n      <td>9.338737</td>\n      <td>5.328691</td>\n      <td>6.631454</td>\n      <td>2.894163</td>\n      <td>3.522526</td>\n      <td>3.191712</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 54675 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"her = pd.DataFrame(data = df.loc[df.type == \"HER\"])\nbasal = pd.DataFrame(data = df.loc[df.type == \"basal\"])\ncell = pd.DataFrame(data = df.loc[df.type == \"cell_line\"])\nlum_A = pd.DataFrame(data = df.loc[df.type == \"luminal_A\"])\nlum_B = pd.DataFrame(data = df.loc[df.type == \"luminal_B\"])\nnorm = pd.DataFrame(data = df.loc[df.type == \"normal\"])\nclasses = {\"her\" : her, \"basal\" : basal, \"cell\" : cell, \"lum_A\" : lum_A, \"lum_B\" : lum_B, \"normal\" : norm}\nclasses_cancer = { \"her\" : her, \"basal\" : basal, \"cell\" : cell, \"lum_A\" : lum_A, \"lum_B\" : lum_B}","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:47.534752Z","iopub.execute_input":"2023-09-11T00:30:47.535316Z","iopub.status.idle":"2023-09-11T00:30:47.616628Z","shell.execute_reply.started":"2023-09-11T00:30:47.535275Z","shell.execute_reply":"2023-09-11T00:30:47.615373Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection using ANOVA","metadata":{}},{"cell_type":"code","source":"from scipy.stats import f_oneway\n\nexcesive_columns = []\nfor name in numerical_columns:\n    for class_1 in classes_cancer:\n        result, p = f_oneway(classes[class_1][name], classes[\"normal\"][name])\n        if p >= 0.01 : \n            excesive_columns.append(name)\n            \n    excesive_columns = list(set(excesive_columns))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:30:47.804689Z","iopub.execute_input":"2023-09-11T00:30:47.805145Z","iopub.status.idle":"2023-09-11T00:35:01.509651Z","shell.execute_reply.started":"2023-09-11T00:30:47.805111Z","shell.execute_reply":"2023-09-11T00:35:01.508764Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns = excesive_columns)\nlen(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:35:41.096166Z","iopub.execute_input":"2023-09-11T00:35:41.096650Z","iopub.status.idle":"2023-09-11T00:35:41.130070Z","shell.execute_reply.started":"2023-09-11T00:35:41.096616Z","shell.execute_reply":"2023-09-11T00:35:41.128784Z"},"trusted":true},"execution_count":242,"outputs":[{"execution_count":242,"output_type":"execute_result","data":{"text/plain":"7573"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\ntransformed = ohe.fit_transform(df[['type']])\nprint(ohe.categories_)\ndf[ohe.categories_[0]] = transformed.toarray()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:35:46.099705Z","iopub.execute_input":"2023-09-11T00:35:46.100630Z","iopub.status.idle":"2023-09-11T00:35:46.151514Z","shell.execute_reply.started":"2023-09-11T00:35:46.100584Z","shell.execute_reply":"2023-09-11T00:35:46.150391Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stdout","text":"[array(['HER', 'basal', 'cell_line', 'luminal_A', 'luminal_B', 'normal'],\n      dtype=object)]\n","output_type":"stream"},{"execution_count":243,"output_type":"execute_result","data":{"text/plain":"   samples   type   1053_at  1552263_at  1552264_a_at  1552277_a_at  \\\n0       84  basal  8.097927    6.468291      8.671009      8.107136   \n1       85  basal  8.212222    6.756707      8.105795      7.505800   \n2       87  basal  8.936137    5.476936      8.752115      7.072525   \n3       90  basal  7.357148    5.985232      7.205984      7.164589   \n4       91  basal  7.746404    6.386138      7.732480      8.225413   \n\n   1552291_at  1552312_a_at  1552315_at  1552316_a_at  ...  \\\n0    5.942088      5.831303    5.733147      5.872538  ...   \n1    6.294126      6.003129    5.995418      5.950860  ...   \n2    7.258626      5.970388    5.433123      4.593427  ...   \n3    6.300199      6.225947    6.788544      7.362372  ...   \n4    6.217526      6.083687    6.265118      6.407850  ...   \n\n   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n0             11.852955            13.658701            13.477698   \n1             11.809408            13.750086            13.470146   \n2             11.725766            13.621732            13.295080   \n3             11.719215            13.743108            13.508861   \n4             11.861296            13.797774            13.542206   \n\n   AFFX-ThrX-3_at  HER  basal  cell_line  luminal_A  luminal_B  normal  \n0        6.265781  0.0    1.0        0.0        0.0        0.0     0.0  \n1        6.771853  0.0    1.0        0.0        0.0        0.0     0.0  \n2        6.346952  0.0    1.0        0.0        0.0        0.0     0.0  \n3        6.610284  0.0    1.0        0.0        0.0        0.0     0.0  \n4        6.414354  0.0    1.0        0.0        0.0        0.0     0.0  \n\n[5 rows x 7579 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>samples</th>\n      <th>type</th>\n      <th>1053_at</th>\n      <th>1552263_at</th>\n      <th>1552264_a_at</th>\n      <th>1552277_a_at</th>\n      <th>1552291_at</th>\n      <th>1552312_a_at</th>\n      <th>1552315_at</th>\n      <th>1552316_a_at</th>\n      <th>...</th>\n      <th>AFFX-r2-Ec-bioD-5_at</th>\n      <th>AFFX-r2-P1-cre-3_at</th>\n      <th>AFFX-r2-P1-cre-5_at</th>\n      <th>AFFX-ThrX-3_at</th>\n      <th>HER</th>\n      <th>basal</th>\n      <th>cell_line</th>\n      <th>luminal_A</th>\n      <th>luminal_B</th>\n      <th>normal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84</td>\n      <td>basal</td>\n      <td>8.097927</td>\n      <td>6.468291</td>\n      <td>8.671009</td>\n      <td>8.107136</td>\n      <td>5.942088</td>\n      <td>5.831303</td>\n      <td>5.733147</td>\n      <td>5.872538</td>\n      <td>...</td>\n      <td>11.852955</td>\n      <td>13.658701</td>\n      <td>13.477698</td>\n      <td>6.265781</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85</td>\n      <td>basal</td>\n      <td>8.212222</td>\n      <td>6.756707</td>\n      <td>8.105795</td>\n      <td>7.505800</td>\n      <td>6.294126</td>\n      <td>6.003129</td>\n      <td>5.995418</td>\n      <td>5.950860</td>\n      <td>...</td>\n      <td>11.809408</td>\n      <td>13.750086</td>\n      <td>13.470146</td>\n      <td>6.771853</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87</td>\n      <td>basal</td>\n      <td>8.936137</td>\n      <td>5.476936</td>\n      <td>8.752115</td>\n      <td>7.072525</td>\n      <td>7.258626</td>\n      <td>5.970388</td>\n      <td>5.433123</td>\n      <td>4.593427</td>\n      <td>...</td>\n      <td>11.725766</td>\n      <td>13.621732</td>\n      <td>13.295080</td>\n      <td>6.346952</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90</td>\n      <td>basal</td>\n      <td>7.357148</td>\n      <td>5.985232</td>\n      <td>7.205984</td>\n      <td>7.164589</td>\n      <td>6.300199</td>\n      <td>6.225947</td>\n      <td>6.788544</td>\n      <td>7.362372</td>\n      <td>...</td>\n      <td>11.719215</td>\n      <td>13.743108</td>\n      <td>13.508861</td>\n      <td>6.610284</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>91</td>\n      <td>basal</td>\n      <td>7.746404</td>\n      <td>6.386138</td>\n      <td>7.732480</td>\n      <td>8.225413</td>\n      <td>6.217526</td>\n      <td>6.083687</td>\n      <td>6.265118</td>\n      <td>6.407850</td>\n      <td>...</td>\n      <td>11.861296</td>\n      <td>13.797774</td>\n      <td>13.542206</td>\n      <td>6.414354</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 7579 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(columns = ['samples'])","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:35:49.118492Z","iopub.execute_input":"2023-09-11T00:35:49.118952Z","iopub.status.idle":"2023-09-11T00:35:49.131126Z","shell.execute_reply.started":"2023-09-11T00:35:49.118918Z","shell.execute_reply":"2023-09-11T00:35:49.130067Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:35:49.424998Z","iopub.execute_input":"2023-09-11T00:35:49.425443Z","iopub.status.idle":"2023-09-11T00:35:49.432630Z","shell.execute_reply.started":"2023-09-11T00:35:49.425412Z","shell.execute_reply":"2023-09-11T00:35:49.431470Z"},"trusted":true},"execution_count":245,"outputs":[{"execution_count":245,"output_type":"execute_result","data":{"text/plain":"7578"},"metadata":{}}]},{"cell_type":"markdown","source":"### 54677 features reduced to 7578 using ANOVA!","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:35:49.774945Z","iopub.execute_input":"2023-09-11T00:35:49.775985Z","iopub.status.idle":"2023-09-11T00:35:49.810570Z","shell.execute_reply.started":"2023-09-11T00:35:49.775945Z","shell.execute_reply":"2023-09-11T00:35:49.809239Z"},"trusted":true},"execution_count":246,"outputs":[{"execution_count":246,"output_type":"execute_result","data":{"text/plain":"    type   1053_at  1552263_at  1552264_a_at  1552277_a_at  1552291_at  \\\n0  basal  8.097927    6.468291      8.671009      8.107136    5.942088   \n1  basal  8.212222    6.756707      8.105795      7.505800    6.294126   \n2  basal  8.936137    5.476936      8.752115      7.072525    7.258626   \n3  basal  7.357148    5.985232      7.205984      7.164589    6.300199   \n4  basal  7.746404    6.386138      7.732480      8.225413    6.217526   \n\n   1552312_a_at  1552315_at  1552316_a_at  1552318_at  ...  \\\n0      5.831303    5.733147      5.872538    5.002625  ...   \n1      6.003129    5.995418      5.950860    4.776947  ...   \n2      5.970388    5.433123      4.593427    4.416091  ...   \n3      6.225947    6.788544      7.362372    6.195537  ...   \n4      6.083687    6.265118      6.407850    5.411214  ...   \n\n   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n0             11.852955            13.658701            13.477698   \n1             11.809408            13.750086            13.470146   \n2             11.725766            13.621732            13.295080   \n3             11.719215            13.743108            13.508861   \n4             11.861296            13.797774            13.542206   \n\n   AFFX-ThrX-3_at  HER  basal  cell_line  luminal_A  luminal_B  normal  \n0        6.265781  0.0    1.0        0.0        0.0        0.0     0.0  \n1        6.771853  0.0    1.0        0.0        0.0        0.0     0.0  \n2        6.346952  0.0    1.0        0.0        0.0        0.0     0.0  \n3        6.610284  0.0    1.0        0.0        0.0        0.0     0.0  \n4        6.414354  0.0    1.0        0.0        0.0        0.0     0.0  \n\n[5 rows x 7578 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>1053_at</th>\n      <th>1552263_at</th>\n      <th>1552264_a_at</th>\n      <th>1552277_a_at</th>\n      <th>1552291_at</th>\n      <th>1552312_a_at</th>\n      <th>1552315_at</th>\n      <th>1552316_a_at</th>\n      <th>1552318_at</th>\n      <th>...</th>\n      <th>AFFX-r2-Ec-bioD-5_at</th>\n      <th>AFFX-r2-P1-cre-3_at</th>\n      <th>AFFX-r2-P1-cre-5_at</th>\n      <th>AFFX-ThrX-3_at</th>\n      <th>HER</th>\n      <th>basal</th>\n      <th>cell_line</th>\n      <th>luminal_A</th>\n      <th>luminal_B</th>\n      <th>normal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>basal</td>\n      <td>8.097927</td>\n      <td>6.468291</td>\n      <td>8.671009</td>\n      <td>8.107136</td>\n      <td>5.942088</td>\n      <td>5.831303</td>\n      <td>5.733147</td>\n      <td>5.872538</td>\n      <td>5.002625</td>\n      <td>...</td>\n      <td>11.852955</td>\n      <td>13.658701</td>\n      <td>13.477698</td>\n      <td>6.265781</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>basal</td>\n      <td>8.212222</td>\n      <td>6.756707</td>\n      <td>8.105795</td>\n      <td>7.505800</td>\n      <td>6.294126</td>\n      <td>6.003129</td>\n      <td>5.995418</td>\n      <td>5.950860</td>\n      <td>4.776947</td>\n      <td>...</td>\n      <td>11.809408</td>\n      <td>13.750086</td>\n      <td>13.470146</td>\n      <td>6.771853</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>basal</td>\n      <td>8.936137</td>\n      <td>5.476936</td>\n      <td>8.752115</td>\n      <td>7.072525</td>\n      <td>7.258626</td>\n      <td>5.970388</td>\n      <td>5.433123</td>\n      <td>4.593427</td>\n      <td>4.416091</td>\n      <td>...</td>\n      <td>11.725766</td>\n      <td>13.621732</td>\n      <td>13.295080</td>\n      <td>6.346952</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basal</td>\n      <td>7.357148</td>\n      <td>5.985232</td>\n      <td>7.205984</td>\n      <td>7.164589</td>\n      <td>6.300199</td>\n      <td>6.225947</td>\n      <td>6.788544</td>\n      <td>7.362372</td>\n      <td>6.195537</td>\n      <td>...</td>\n      <td>11.719215</td>\n      <td>13.743108</td>\n      <td>13.508861</td>\n      <td>6.610284</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>basal</td>\n      <td>7.746404</td>\n      <td>6.386138</td>\n      <td>7.732480</td>\n      <td>8.225413</td>\n      <td>6.217526</td>\n      <td>6.083687</td>\n      <td>6.265118</td>\n      <td>6.407850</td>\n      <td>5.411214</td>\n      <td>...</td>\n      <td>11.861296</td>\n      <td>13.797774</td>\n      <td>13.542206</td>\n      <td>6.414354</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 7578 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# for backup\nfrom copy import deepcopy\ndf_backup = deepcopy(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:35:58.024852Z","iopub.execute_input":"2023-09-11T00:35:58.025940Z","iopub.status.idle":"2023-09-11T00:35:58.042177Z","shell.execute_reply.started":"2023-09-11T00:35:58.025898Z","shell.execute_reply":"2023-09-11T00:35:58.040915Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"df = deepcopy(df_backup)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:44:59.019931Z","iopub.execute_input":"2023-09-11T00:44:59.020453Z","iopub.status.idle":"2023-09-11T00:44:59.028903Z","shell.execute_reply.started":"2023-09-11T00:44:59.020414Z","shell.execute_reply":"2023-09-11T00:44:59.027793Z"},"trusted":true},"execution_count":396,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:45:07.014897Z","iopub.execute_input":"2023-09-11T00:45:07.016174Z","iopub.status.idle":"2023-09-11T00:45:07.021594Z","shell.execute_reply.started":"2023-09-11T00:45:07.016128Z","shell.execute_reply":"2023-09-11T00:45:07.020263Z"},"trusted":true},"execution_count":405,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:45:16.375042Z","iopub.execute_input":"2023-09-11T00:45:16.375513Z","iopub.status.idle":"2023-09-11T00:45:16.381712Z","shell.execute_reply.started":"2023-09-11T00:45:16.375480Z","shell.execute_reply":"2023-09-11T00:45:16.380574Z"},"trusted":true},"execution_count":410,"outputs":[]},{"cell_type":"markdown","source":"## Mutual Information-based feature selection","metadata":{}},{"cell_type":"code","source":"df = deepcopy(df_backup)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:01:13.136159Z","iopub.execute_input":"2023-09-11T01:01:13.136666Z","iopub.status.idle":"2023-09-11T01:01:13.145403Z","shell.execute_reply.started":"2023-09-11T01:01:13.136630Z","shell.execute_reply":"2023-09-11T01:01:13.144061Z"},"trusted":true},"execution_count":436,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\ndf['type'] = label_encoder.fit_transform(df['type'])\n\nX = df.drop(columns=['type'],axis=1).values\ny = df['type']\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:53:05.059928Z","iopub.execute_input":"2023-09-11T00:53:05.060869Z","iopub.status.idle":"2023-09-11T00:53:05.096883Z","shell.execute_reply.started":"2023-09-11T00:53:05.060826Z","shell.execute_reply":"2023-09-11T00:53:05.095777Z"},"trusted":true},"execution_count":428,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:53:07.095413Z","iopub.execute_input":"2023-09-11T00:53:07.096286Z","iopub.status.idle":"2023-09-11T00:53:07.101162Z","shell.execute_reply.started":"2023-09-11T00:53:07.096249Z","shell.execute_reply":"2023-09-11T00:53:07.099792Z"},"trusted":true},"execution_count":429,"outputs":[]},{"cell_type":"code","source":"k = 20\nselector = SelectKBest(mutual_info_classif, k=k)\nX_new = selector.fit_transform(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:53:07.500165Z","iopub.execute_input":"2023-09-11T00:53:07.500614Z","iopub.status.idle":"2023-09-11T00:54:00.661216Z","shell.execute_reply.started":"2023-09-11T00:53:07.500580Z","shell.execute_reply":"2023-09-11T00:54:00.660273Z"},"trusted":true},"execution_count":430,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_new, y,test_size = 0.3)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:55:01.684906Z","iopub.execute_input":"2023-09-11T00:55:01.685910Z","iopub.status.idle":"2023-09-11T00:55:01.692817Z","shell.execute_reply.started":"2023-09-11T00:55:01.685869Z","shell.execute_reply":"2023-09-11T00:55:01.691488Z"},"trusted":true},"execution_count":431,"outputs":[]},{"cell_type":"code","source":"\nkfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Performing 10-fold cross-validation\nscores = cross_val_score(rf_classifier, X_train, y_train, cv=kfold, scoring='accuracy')\n\nprint(\"Cross-validation scores:\", scores)\nprint(\"Mean accuracy:\", scores.mean())\n\nrf_classifier.fit(X_train, y_train)\ny_pred = rf_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Test set accuracy:\", accuracy)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:51:50.465506Z","iopub.execute_input":"2023-09-11T00:51:50.465986Z","iopub.status.idle":"2023-09-11T00:51:51.368338Z","shell.execute_reply.started":"2023-09-11T00:51:50.465952Z","shell.execute_reply":"2023-09-11T00:51:51.367228Z"},"trusted":true},"execution_count":424,"outputs":[{"name":"stdout","text":"Cross-validation scores: [0.88571429 0.8        0.91428571]\nMean accuracy: 0.8666666666666667\nTest set accuracy: 0.8695652173913043\nClassification Report:\n              precision    recall  f1-score   support\n\n         HER       0.70      1.00      0.82         7\n       basal       0.89      0.73      0.80        11\n   cell_line       1.00      0.80      0.89         5\n   luminal_A       0.83      1.00      0.91        10\n   luminal_B       1.00      0.89      0.94         9\n      normal       1.00      0.75      0.86         4\n\n    accuracy                           0.87        46\n   macro avg       0.90      0.86      0.87        46\nweighted avg       0.89      0.87      0.87        46\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:55:16.255358Z","iopub.execute_input":"2023-09-11T00:55:16.256943Z","iopub.status.idle":"2023-09-11T00:55:16.263014Z","shell.execute_reply.started":"2023-09-11T00:55:16.256884Z","shell.execute_reply":"2023-09-11T00:55:16.261552Z"},"trusted":true},"execution_count":433,"outputs":[]},{"cell_type":"code","source":"xgb_classifier = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100, random_state=42)\nxgb_classifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:55:17.460623Z","iopub.execute_input":"2023-09-11T00:55:17.461105Z","iopub.status.idle":"2023-09-11T00:55:17.623661Z","shell.execute_reply.started":"2023-09-11T00:55:17.461054Z","shell.execute_reply":"2023-09-11T00:55:17.622794Z"},"trusted":true},"execution_count":434,"outputs":[{"execution_count":434,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              objective='multi:softprob', predictor=None, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = xgb_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Test set accuracy:\", accuracy)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:55:37.785659Z","iopub.execute_input":"2023-09-11T00:55:37.786157Z","iopub.status.idle":"2023-09-11T00:55:37.805690Z","shell.execute_reply.started":"2023-09-11T00:55:37.786118Z","shell.execute_reply":"2023-09-11T00:55:37.804807Z"},"trusted":true},"execution_count":435,"outputs":[{"name":"stdout","text":"Test set accuracy: 0.8913043478260869\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.75      1.00      0.86         6\n           1       1.00      1.00      1.00        13\n           2       1.00      0.80      0.89         5\n           3       0.62      1.00      0.77         5\n           4       1.00      0.79      0.88        14\n           5       1.00      0.67      0.80         3\n\n    accuracy                           0.89        46\n   macro avg       0.90      0.88      0.87        46\nweighted avg       0.93      0.89      0.89        46\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Autoencoder for dimensionality reduction","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:01:18.339778Z","iopub.execute_input":"2023-09-11T01:01:18.340243Z","iopub.status.idle":"2023-09-11T01:01:27.141955Z","shell.execute_reply.started":"2023-09-11T01:01:18.340207Z","shell.execute_reply":"2023-09-11T01:01:27.141062Z"},"trusted":true},"execution_count":437,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf['type'] = label_encoder.fit_transform(df['type'])\nX = df.drop(columns=['type'], axis=1).values\ny = df['type']\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:19:17.831059Z","iopub.execute_input":"2023-09-11T01:19:17.831505Z","iopub.status.idle":"2023-09-11T01:19:17.860244Z","shell.execute_reply.started":"2023-09-11T01:19:17.831471Z","shell.execute_reply":"2023-09-11T01:19:17.859147Z"},"trusted":true},"execution_count":461,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:22:28.854593Z","iopub.execute_input":"2023-09-11T01:22:28.855030Z","iopub.status.idle":"2023-09-11T01:22:28.862887Z","shell.execute_reply.started":"2023-09-11T01:22:28.854997Z","shell.execute_reply":"2023-09-11T01:22:28.861719Z"},"trusted":true},"execution_count":474,"outputs":[{"execution_count":474,"output_type":"execute_result","data":{"text/plain":"(151, 7577)"},"metadata":{}}]},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:19:08.464601Z","iopub.execute_input":"2023-09-11T01:19:08.465054Z","iopub.status.idle":"2023-09-11T01:19:08.472027Z","shell.execute_reply.started":"2023-09-11T01:19:08.465022Z","shell.execute_reply":"2023-09-11T01:19:08.470620Z"},"trusted":true},"execution_count":460,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n\ninput_dim = X_train.shape[1]\nencoding_dim = 32\nhidden_dim = 32\n\nautoencoder = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=(input_dim,)),\n    tf.keras.layers.Dense(hidden_dim, activation='relu'),\n    tf.keras.layers.Dense(encoding_dim, activation='relu'),  # The bottleneck layer\n    tf.keras.layers.Dense(hidden_dim, activation='relu'),\n    tf.keras.layers.Dense(input_dim, activation='sigmoid')\n])\n\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')\nautoencoder.fit(X_train, X_train, epochs=100, batch_size=32, shuffle=True, validation_data=(X_test, X_test))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:46.141191Z","iopub.execute_input":"2023-09-11T01:35:46.141648Z","iopub.status.idle":"2023-09-11T01:35:57.410689Z","shell.execute_reply.started":"2023-09-11T01:35:46.141616Z","shell.execute_reply":"2023-09-11T01:35:57.409039Z"},"trusted":true},"execution_count":563,"outputs":[{"name":"stdout","text":"Epoch 1/100\n4/4 [==============================] - 1s 70ms/step - loss: 1.3076 - val_loss: 1.1041\nEpoch 2/100\n4/4 [==============================] - 0s 22ms/step - loss: 1.2397 - val_loss: 1.0487\nEpoch 3/100\n4/4 [==============================] - 0s 21ms/step - loss: 1.1480 - val_loss: 0.9875\nEpoch 4/100\n4/4 [==============================] - 0s 21ms/step - loss: 1.0722 - val_loss: 0.9307\nEpoch 5/100\n4/4 [==============================] - 0s 25ms/step - loss: 1.0160 - val_loss: 0.8836\nEpoch 6/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.9630 - val_loss: 0.8526\nEpoch 7/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.9348 - val_loss: 0.8340\nEpoch 8/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.9190 - val_loss: 0.8209\nEpoch 9/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.9088 - val_loss: 0.8130\nEpoch 10/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.9017 - val_loss: 0.8086\nEpoch 11/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8960 - val_loss: 0.8054\nEpoch 12/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8915 - val_loss: 0.8022\nEpoch 13/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8875 - val_loss: 0.7987\nEpoch 14/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8837 - val_loss: 0.7964\nEpoch 15/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8817 - val_loss: 0.7946\nEpoch 16/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8791 - val_loss: 0.7923\nEpoch 17/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8761 - val_loss: 0.7907\nEpoch 18/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8736 - val_loss: 0.7901\nEpoch 19/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8715 - val_loss: 0.7881\nEpoch 20/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8691 - val_loss: 0.7856\nEpoch 21/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8664 - val_loss: 0.7839\nEpoch 22/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8646 - val_loss: 0.7830\nEpoch 23/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8627 - val_loss: 0.7826\nEpoch 24/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8602 - val_loss: 0.7821\nEpoch 25/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8578 - val_loss: 0.7812\nEpoch 26/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8558 - val_loss: 0.7801\nEpoch 27/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8539 - val_loss: 0.7797\nEpoch 28/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8524 - val_loss: 0.7794\nEpoch 29/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8507 - val_loss: 0.7785\nEpoch 30/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8484 - val_loss: 0.7769\nEpoch 31/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8460 - val_loss: 0.7761\nEpoch 32/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8445 - val_loss: 0.7758\nEpoch 33/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8431 - val_loss: 0.7752\nEpoch 34/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8415 - val_loss: 0.7743\nEpoch 35/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8399 - val_loss: 0.7733\nEpoch 36/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8378 - val_loss: 0.7734\nEpoch 37/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8361 - val_loss: 0.7735\nEpoch 38/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8346 - val_loss: 0.7735\nEpoch 39/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8332 - val_loss: 0.7733\nEpoch 40/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8317 - val_loss: 0.7732\nEpoch 41/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8312 - val_loss: 0.7724\nEpoch 42/100\n4/4 [==============================] - 0s 24ms/step - loss: 0.8302 - val_loss: 0.7724\nEpoch 43/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8288 - val_loss: 0.7724\nEpoch 44/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8275 - val_loss: 0.7709\nEpoch 45/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8269 - val_loss: 0.7706\nEpoch 46/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8249 - val_loss: 0.7707\nEpoch 47/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8232 - val_loss: 0.7705\nEpoch 48/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8220 - val_loss: 0.7700\nEpoch 49/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8206 - val_loss: 0.7697\nEpoch 50/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8193 - val_loss: 0.7701\nEpoch 51/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8183 - val_loss: 0.7699\nEpoch 52/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8174 - val_loss: 0.7693\nEpoch 53/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8162 - val_loss: 0.7693\nEpoch 54/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8148 - val_loss: 0.7703\nEpoch 55/100\n4/4 [==============================] - 0s 26ms/step - loss: 0.8137 - val_loss: 0.7709\nEpoch 56/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8128 - val_loss: 0.7710\nEpoch 57/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8112 - val_loss: 0.7705\nEpoch 58/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8100 - val_loss: 0.7697\nEpoch 59/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8089 - val_loss: 0.7692\nEpoch 60/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8079 - val_loss: 0.7691\nEpoch 61/100\n4/4 [==============================] - 0s 25ms/step - loss: 0.8067 - val_loss: 0.7691\nEpoch 62/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.8057 - val_loss: 0.7692\nEpoch 63/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8047 - val_loss: 0.7692\nEpoch 64/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8036 - val_loss: 0.7690\nEpoch 65/100\n4/4 [==============================] - 0s 27ms/step - loss: 0.8026 - val_loss: 0.7691\nEpoch 66/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.8017 - val_loss: 0.7690\nEpoch 67/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.8007 - val_loss: 0.7685\nEpoch 68/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.7998 - val_loss: 0.7686\nEpoch 69/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7994 - val_loss: 0.7691\nEpoch 70/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.7988 - val_loss: 0.7689\nEpoch 71/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7975 - val_loss: 0.7689\nEpoch 72/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7964 - val_loss: 0.7698\nEpoch 73/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7958 - val_loss: 0.7703\nEpoch 74/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7951 - val_loss: 0.7702\nEpoch 75/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7944 - val_loss: 0.7707\nEpoch 76/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7937 - val_loss: 0.7712\nEpoch 77/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7931 - val_loss: 0.7712\nEpoch 78/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7922 - val_loss: 0.7705\nEpoch 79/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7909 - val_loss: 0.7697\nEpoch 80/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7898 - val_loss: 0.7694\nEpoch 81/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7888 - val_loss: 0.7693\nEpoch 82/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.7879 - val_loss: 0.7693\nEpoch 83/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7870 - val_loss: 0.7696\nEpoch 84/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7864 - val_loss: 0.7711\nEpoch 85/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7866 - val_loss: 0.7716\nEpoch 86/100\n4/4 [==============================] - 0s 25ms/step - loss: 0.7864 - val_loss: 0.7712\nEpoch 87/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7862 - val_loss: 0.7711\nEpoch 88/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7856 - val_loss: 0.7716\nEpoch 89/100\n4/4 [==============================] - 0s 21ms/step - loss: 0.7852 - val_loss: 0.7720\nEpoch 90/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7841 - val_loss: 0.7719\nEpoch 91/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7846 - val_loss: 0.7718\nEpoch 92/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.7844 - val_loss: 0.7727\nEpoch 93/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7840 - val_loss: 0.7732\nEpoch 94/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7832 - val_loss: 0.7728\nEpoch 95/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7828 - val_loss: 0.7733\nEpoch 96/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7827 - val_loss: 0.7736\nEpoch 97/100\n4/4 [==============================] - 0s 22ms/step - loss: 0.7821 - val_loss: 0.7735\nEpoch 98/100\n4/4 [==============================] - 0s 24ms/step - loss: 0.7816 - val_loss: 0.7734\nEpoch 99/100\n4/4 [==============================] - 0s 23ms/step - loss: 0.7811 - val_loss: 0.7733\nEpoch 100/100\n4/4 [==============================] - 0s 25ms/step - loss: 0.7801 - val_loss: 0.7730\n","output_type":"stream"},{"execution_count":563,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79d3fde594e0>"},"metadata":{}}]},{"cell_type":"code","source":"encoder = tf.keras.models.Sequential(autoencoder.layers[:3])\nX_train_encoded = encoder.predict(X_train)\nX_test_encoded = encoder.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:57.413178Z","iopub.execute_input":"2023-09-11T01:35:57.414324Z","iopub.status.idle":"2023-09-11T01:35:57.649637Z","shell.execute_reply.started":"2023-09-11T01:35:57.414287Z","shell.execute_reply":"2023-09-11T01:35:57.648379Z"},"trusted":true},"execution_count":564,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 0s 3ms/step\n2/2 [==============================] - 0s 4ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:57.651639Z","iopub.execute_input":"2023-09-11T01:35:57.652011Z","iopub.status.idle":"2023-09-11T01:35:57.660404Z","shell.execute_reply.started":"2023-09-11T01:35:57.651980Z","shell.execute_reply":"2023-09-11T01:35:57.659137Z"},"trusted":true},"execution_count":565,"outputs":[{"execution_count":565,"output_type":"execute_result","data":{"text/plain":"(98, 32)"},"metadata":{}}]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:57.663225Z","iopub.execute_input":"2023-09-11T01:35:57.663686Z","iopub.status.idle":"2023-09-11T01:35:57.675763Z","shell.execute_reply.started":"2023-09-11T01:35:57.663646Z","shell.execute_reply":"2023-09-11T01:35:57.674493Z"},"trusted":true},"execution_count":566,"outputs":[{"execution_count":566,"output_type":"execute_result","data":{"text/plain":"(53, 7577)"},"metadata":{}}]},{"cell_type":"code","source":"X_test_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:57.677397Z","iopub.execute_input":"2023-09-11T01:35:57.677749Z","iopub.status.idle":"2023-09-11T01:35:57.689044Z","shell.execute_reply.started":"2023-09-11T01:35:57.677718Z","shell.execute_reply":"2023-09-11T01:35:57.688030Z"},"trusted":true},"execution_count":567,"outputs":[{"execution_count":567,"output_type":"execute_result","data":{"text/plain":"(53, 32)"},"metadata":{}}]},{"cell_type":"code","source":"rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_classifier.fit(X_train_encoded, y_train)\ny_pred = rf_classifier.predict(X_test_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:57.690583Z","iopub.execute_input":"2023-09-11T01:35:57.691698Z","iopub.status.idle":"2023-09-11T01:35:57.942239Z","shell.execute_reply.started":"2023-09-11T01:35:57.691663Z","shell.execute_reply":"2023-09-11T01:35:57.940769Z"},"trusted":true},"execution_count":568,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)\nprint(\"Test set accuracy:\", accuracy)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T01:35:57.943863Z","iopub.execute_input":"2023-09-11T01:35:57.944278Z","iopub.status.idle":"2023-09-11T01:35:57.963784Z","shell.execute_reply.started":"2023-09-11T01:35:57.944244Z","shell.execute_reply":"2023-09-11T01:35:57.962197Z"},"trusted":true},"execution_count":569,"outputs":[{"name":"stdout","text":"Test set accuracy: 0.8301886792452831\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.78      0.78      0.78         9\n           1       0.94      0.94      0.94        17\n           2       1.00      1.00      1.00         6\n           3       0.55      0.86      0.67         7\n           4       0.89      0.62      0.73        13\n           5       1.00      1.00      1.00         1\n\n    accuracy                           0.83        53\n   macro avg       0.86      0.87      0.85        53\nweighted avg       0.86      0.83      0.83        53\n\n","output_type":"stream"}]}]}